# Financial Portofolio Management with Reinforcement Learning

# DQN vs PPO in Algorithmic Trading: A Reinforcement Learning Comparison

# Overview
This repository explores the application of Deep Q-Networks (DQN) and Proximal Policy Optimization (PPO) in algorithmic trading. It provides a comprehensive comparison of both reinforcement learning (RL) models, discussing their strengths, weaknesses, and ideal use cases in financial markets.

# Key Topics Covered
Introduction to Reinforcement Learning (RL) in Trading
How DQN and PPO Work

# Advantages and Limitations of Each Model
Use Cases in Market Volatility and Portfolio Optimization
Comparison Table: Choosing Between DQN and PPO for Trading Strategies

# Why This Matters?
With increasing market complexity, RL-based trading models provide a powerful way to optimize decision-making in real-time. This comparison helps traders, data scientists, and researchers understand when to use DQN vs. PPO based on market conditions and trading objectives.

# Repository Contents
  - Article.md – Full breakdown of DQN vs PPO for trading.
  - Comparison_Table.png – Visual summary of key differences.
  - TradingView_Charts/ – Sample market data visualizations.
